{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*WormsPy Post Processing Pipeline*\n",
    "\n",
    "This Jupyter notebook contains code to extract data from WormsPy outputs into CSV data in the following code blocks:\n",
    "1. Formatting step that makes it so a DLC node can be superimposed onto stage position for more exact tracking (of the nose tip for example)\n",
    "2. Master imports and directories for the WormsPy recording you are working on\n",
    "3. Converts folder of tiffs into one tif stack that is the input for the provided segmentation code (separate python file)\n",
    "4. Auto-annotate from curvature and angle data\n",
    "5. Nose-tip translation from DLC file onto stage position for absolute position.\n",
    "6. Combine datafiles.\n",
    "\n",
    "As inputs it requires the folder of .tiff files, the CSV of stage position, and the brightfield .avi produced by a WormsPy recording.\n",
    "\n",
    "As an output it produces a .csv file with mean and sum of fluorescence changes within the ROI, the position of the nose of the animal, and worm curvatures to auto-annotate reversals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format all DLC CSVs correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd # type: ignore\n",
    "# Define the folder containing the CSV files\n",
    "folder_path = 'DLC_FOLDER'\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        if filename.startswith('._'):\n",
    "            continue\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        print(f'Processing file: {file_path}')\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Keep only the first three columns\n",
    "        df = df.iloc[:, :3]\n",
    "\n",
    "        # drop first two rows\n",
    "        df = df.drop([0, 1])\n",
    "        \n",
    "        # Rename the columns\n",
    "        df.columns = ['index', 'x', 'y']\n",
    "\n",
    "        # Convert 'x' and 'y' columns to numeric types\n",
    "        df['x'] = pd.to_numeric(df['x'], errors='coerce')\n",
    "        df['y'] = pd.to_numeric(df['y'], errors='coerce')\n",
    "        \n",
    "        # Calculate the differences for X and Y columns\n",
    "        df['X_diff'] = df['x'].diff().abs()\n",
    "        df['Y_diff'] = df['y'].diff().abs()\n",
    "\n",
    "        # Replace values where the difference is above 30 pixels\n",
    "        df.loc[df['X_diff'] > 30, 'x'] = df['x'].shift()\n",
    "        df.loc[df['Y_diff'] > 30, 'y'] = df['y'].shift()\n",
    "\n",
    "        # smooth the series\n",
    "        df['x'] = df['x'].rolling(window=3, min_periods=1).mean()\n",
    "        df['y'] = df['y'].rolling(window=3, min_periods=1).mean()\n",
    "\n",
    "        # round the values to 0 decimal places\n",
    "        df['x'] = df['x'].round(0)\n",
    "        df['y'] = df['y'].round(0)\n",
    "        \n",
    "        # Save the modified DataFrame back to a CSV file\n",
    "        df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports for all code blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tifffile\n",
    "import numpy as np\n",
    "import re\n",
    "import cv2\n",
    "import csv\n",
    "import imageio\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "directory = \"DIRECTORY\" # directory of the WormsPy output folder\n",
    "name = \"NAME\" # desired name\n",
    "stagepos_csv = os.path.join(directory, name + '_stagepos.csv') # input file\n",
    "annotatedcsv = os.path.join(directory, name + '_annotated.csv') # output file\n",
    "segmented_csv_path = os.path.join(directory, name + '_segmented.csv') #input file\n",
    "\n",
    "\n",
    "# Read the DLC CSV file\n",
    "DLC_file = os.path.join(directory, name + 'DLC.csv') # input file\n",
    "nosepos_csv = os.path.join(directory, name + '_nosecoords.csv') #output file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiffstacker: This script converts a folder of images into a single .tiff stack that can by dynamically segmented. Run Segmentation scipt on this tiff stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_sort(value):\n",
    "    numbers = re.findall(r'\\d+', value)\n",
    "    return int(numbers[0]) if numbers else 0\n",
    "\n",
    "def tiff_stacker(dir_path, output_path):\n",
    "    # Get a list of all TIFF files in the directory\n",
    "    tiff_files = [file for file in os.listdir(dir_path) if file.endswith('.tiff')]\n",
    "\n",
    "    # Sort the TIFF files numerically\n",
    "    tiff_files.sort(key=numerical_sort)\n",
    "\n",
    "    # Read the first image to determine its shape and data type\n",
    "    first_image = tifffile.imread(os.path.join(dir_path, tiff_files[0]))\n",
    "\n",
    "    # Initialize an empty stack with appropriate dimensions and data type\n",
    "    stack = np.zeros((len(tiff_files), first_image.shape[0], first_image.shape[1]), dtype=first_image.dtype)\n",
    "\n",
    "    # Read each TIFF file and add it to the stack\n",
    "    for i, tiff_file in enumerate(tiff_files):\n",
    "        image = tifffile.imread(os.path.join(dir_path, tiff_file))\n",
    "        stack[i] = image\n",
    "\n",
    "    # Save the stack as a multi-image TIFF file\n",
    "    tifffile.imwrite(output_path, stack)\n",
    "\n",
    "    print(f\"Multi-image TIFF stack saved at {output_path}\")\n",
    "\n",
    "for foldername in os.listdir(directory):\n",
    "    input_path = os.path.join(directory, foldername)\n",
    "    if os.path.isdir(input_path):  # Ensure input_path is a directory\n",
    "        output_path = os.path.join(directory, name + \".tiff\") #output name\n",
    "        tiff_stacker(input_path, output_path)\n",
    "    else:\n",
    "        print(f\"{input_path} is not a directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auto-Annotate: Takes the CSV of stage position recordings and calculates the angle and curvature for each frame to find instances of likely reversals. Recommended you manually check the annotations and filter out false positives. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vertex_angles(x, y):\n",
    "    n = len(x)\n",
    "    if n < 3:\n",
    "        raise ValueError('At least three points are required to calculate angles.')\n",
    "    \n",
    "    angles = np.zeros(n-2)\n",
    "    \n",
    "    for i in range(1, n-1):\n",
    "        BA_x = x[i-1] - x[i]\n",
    "        BA_y = y[i-1] - y[i]\n",
    "        BC_x = x[i+1] - x[i]\n",
    "        BC_y = y[i+1] - y[i]\n",
    "        \n",
    "        dot_product = BA_x * BC_x + BA_y * BC_y\n",
    "        magnitude_BA = np.sqrt(BA_x**2 + BA_y**2)\n",
    "        magnitude_BC = np.sqrt(BC_x**2 + BC_y**2)\n",
    "        \n",
    "        cos_theta = dot_product / (magnitude_BA * magnitude_BC)\n",
    "        angle_radians = np.arccos(cos_theta)\n",
    "        angles[i-1] = np.degrees(angle_radians)\n",
    "    \n",
    "    return angles\n",
    "\n",
    "def calculate_three_point_curvatures(x, y):\n",
    "    n = len(x)\n",
    "    curvatures = np.zeros(n-2)\n",
    "    \n",
    "    for i in range(1, n-1):\n",
    "        x1, y1 = x[i-1], y[i-1]\n",
    "        x2, y2 = x[i], y[i]\n",
    "        x3, y3 = x[i+1], y[i+1]\n",
    "        \n",
    "        num = abs((x2 - x1) * (y3 - y1) - (y2 - y1) * (x3 - x1))\n",
    "        den = np.sqrt(((x2 - x1)**2 + (y2 - y1)**2) * ((x3 - x1)**2 + (y3 - y1)**2) * ((x3 - x2)**2 + (y3 - y2)**2))\n",
    "        \n",
    "        if den != 0:\n",
    "            curvatures[i-1] = 2 * num / den\n",
    "        else:\n",
    "            curvatures[i-1] = 0\n",
    "    \n",
    "    return curvatures\n",
    "\n",
    "# edit angle_threshold and curvature_threshold as needed\n",
    "def auto_annotate(ax, x, y, angle_threshold=10, curvature_threshold=0.05):\n",
    "    angles = get_vertex_angles(x, y)\n",
    "    curvatures = calculate_three_point_curvatures(x, y)\n",
    "    \n",
    "    n = len(x)\n",
    "    \n",
    "    for i in range(1, n-1):\n",
    "        if angles[i-1] > angle_threshold:\n",
    "            ax.plot(x[i], y[i], 'bo', markersize=5)\n",
    "        \n",
    "        if curvatures[i-1] > curvature_threshold:\n",
    "            ax.plot(x[i], y[i], 'ro', markersize=5)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(stagepos_csv)\n",
    "    data = pd.read_csv(stagepos_csv)\n",
    "    x = data['X_motor'].values\n",
    "    y = data['Y_motor'].values\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    auto_annotate(ax, x, y)\n",
    "    plt.show()\n",
    "\n",
    "    data = data.drop([0, 1])\n",
    "    \n",
    "    curvatures = calculate_three_point_curvatures(x, y)\n",
    "    data['Curvatures'] = np.concatenate((np.array([0]), curvatures[:-2], np.array([0])))\n",
    "    \n",
    "    angles = get_vertex_angles(x, y)\n",
    "    data['Angles'] = np.concatenate((np.array([0]), angles[:-2], np.array([0])))\n",
    "    angle_threshold=30\n",
    "    curvature_threshold=0.03\n",
    "    data['Reversals'] = ((data['Curvatures'] > curvature_threshold) & (data['Angles'] < angle_threshold)).astype(int)\n",
    "\n",
    "    data.to_csv(annotatedcsv, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For finer tuned behavioural annotation we recommend using DeepLabCut that can be trained for your specifications.\n",
    "\n",
    "Nose Tip Translation: This code takes the pixel coordinates of a point of interest from DLC (like the nose tip) and adds it onto the stage position in uM. DLC CSV will need to be formatted to drop the unnecessary rows and drop all columns besides the X and Y for the desired point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the midpoint of the video (resolution / 2) CHANGE IF NEEDED\n",
    "midpoint_x = 960\n",
    "midpoint_y = 600\n",
    "pxtouM = 1.54\n",
    " \n",
    "# Open the DLC file and read the X and Y columns, subtracting midpoint_x and midpoint_y\n",
    "with open(DLC_file, 'r') as dlc_csv:\n",
    "    dlc_reader = csv.DictReader(dlc_csv)\n",
    "    dlc_data = [((float(row['x']) - midpoint_x)*pxtouM, ((float(row['y']) - midpoint_y)*pxtouM)) for row in dlc_reader]    \n",
    "\n",
    "# Open the stage file and read the data\n",
    "with open(annotatedcsv, 'r') as stage_csv:\n",
    "    stage_reader = csv.DictReader(stage_csv)\n",
    "    stage_data = [row for row in stage_reader]\n",
    "    stage_fieldnames = stage_reader.fieldnames\n",
    "\n",
    "# Add new columns for X_nose and Y_nose\n",
    "stage_fieldnames.extend(['X_nose', 'Y_nose'])\n",
    "\n",
    "# Combine the data and write to a new CSV file\n",
    "with open(nosepos_csv, 'w', newline='') as output_csv:\n",
    "    writer = csv.DictWriter(output_csv, fieldnames=stage_fieldnames)\n",
    "    writer.writeheader()\n",
    "    for i, row in enumerate(stage_data):\n",
    "        row['X_nose'] = float(row['X_motor']) + dlc_data[i][0]\n",
    "        row['Y_nose'] = float(row['Y_motor']) - dlc_data[i][1]\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the position data with the segmentation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the nose position CSV\n",
    "position_data = pd.read_csv(nosepos_csv)\n",
    "\n",
    "# Read the segmentation CSV\n",
    "segmentation_data = pd.read_csv(segmented_csv_path)\n",
    "\n",
    "# Join the two data tables based on row number\n",
    "combined_data = pd.concat([segmentation_data, position_data], axis=1)\n",
    "\n",
    "# Write the combined data to a new CSV\n",
    "combined_csv_path = os.path.join(directory, name + \"_combined.csv\")\n",
    "combined_data.to_csv(combined_csv_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
